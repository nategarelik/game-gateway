# End-to-End Test Scenario 01: Level Design with Asset Generation

**Scenario Script:** [`scripts/run_end_to_end_scenario_01.py`](../../scripts/run_end_to_end_scenario_01.py)

## Purpose

This end-to-end test scenario simulates a basic workflow involving multiple components of the Autonomous AI Agent Ecosystem. The primary goal is to verify a conceptual flow where a level design task leads to an asset generation request, involving agent logic (simplified) and toolchain interaction (mocked).

## Scenario Overview

1.  **Initialization:**
    *   A mock Master Control Program (MCP) is simulated (primarily through an `event_log`).
    *   Relevant toolchains (`RetroDiffusionBridge`) are initialized.
    *   Key agents (`LevelArchitectAgent` - or a placeholder if its full init is complex) are initialized.

2.  **Task Dispatch (Simulated MCP):**
    *   The mock MCP dispatches a high-level task to the `LevelArchitectAgent` to design a specific level area (e.g., "enchanted forest clearing").

3.  **Level Architect Design Phase (Simplified):**
    *   The `LevelArchitectAgent` (via a scenario-specific function `run_level_architect_design_phase`) begins processing the design task.
    *   It conceptualizes the level layout (mocked step).
    *   It identifies a need for a specific asset (e.g., "a vibrant, glowing mushroom sprite").

4.  **Asset Request & Generation (Simplified Agent & Toolchain Interaction):**
    *   The `LevelArchitectAgent` requires the asset. In a full system, it would create a new MCP task for the `PixelForgeAgent`.
    *   **For this scenario's simplification:** The `LevelArchitectAgent` directly invokes the `RetroDiffusionBridge` (which the `PixelForgeAgent` would normally use internally) to request the "glowing mushroom sprite".
    *   The `RetroDiffusionBridge` processes this request (using its mock generation logic) and returns information about the (mock) generated asset.

5.  **Asset Integration & Task Completion (Simplified):**
    *   The `LevelArchitectAgent` receives the asset information from the bridge.
    *   It conceptually integrates this asset into its level design.
    *   It marks its main design task as complete.

6.  **Event Logging:**
    *   Throughout the scenario, key actions and state changes are logged to a global `event_log` list. This includes task reception, design progress, asset requirements, toolchain requests/responses, and task completion.

7.  **Output:**
    *   The script prints the full `event_log` at the end, allowing verification of the sequence of operations.
    *   The script also demonstrates shutting down the toolchain bridges.

## Components Involved (and their roles in this scenario)

*   **`LevelArchitectAgent` (or Placeholder):**
    *   Receives the main design task.
    *   Identifies the need for a specific visual asset.
    *   Initiates the request for this asset (simplified to directly use the toolchain bridge).
*   **`PixelForgeAgent`:**
    *   Not directly instantiated or tasked in this simplified script. Its role (asset generation using toolchains) is effectively performed by the `LevelArchitectAgent` directly calling the `RetroDiffusionBridge`.
*   **`RetroDiffusionBridge`:**
    *   Called by the `LevelArchitectAgent` to generate the required image asset.
    *   Uses its internal mock logic to simulate asset creation and returns a result.
*   **Mock MCP / Scenario Runner:**
    *   Simulates task dispatch.
    *   Collects events in `event_log`.
    *   Orchestrates the overall flow of the scenario script.

## Expected Outcome & Verification

The primary verification is through the `event_log` printed at the end of the script. The log should show a logical sequence of events, including:
1.  MCP (simulator) initializing and dispatching the design task to the Level Architect.
2.  Level Architect receiving the task and starting design conceptualization.
3.  Level Architect identifying the need for a specific asset.
4.  Level Architect sending a request to the `RetroDiffusionBridge`.
5.  `RetroDiffusionBridge` acknowledging the request, processing it (mocked), and returning a (mock) success response with asset details.
6.  Level Architect receiving the toolchain response and integrating the asset.
7.  Level Architect completing its design task.
8.  MCP (simulator) scenario completion event.

The mock asset file generated by `RetroDiffusionBridge` should also be created in the `generated_assets/retro_diffusion/` directory (though the script doesn't explicitly verify file content, only that the bridge reports a path).

## How to Run

1.  Ensure all necessary dependencies and Python paths are set up correctly so that components from `src/` can be imported.
2.  Execute the script from the project's root directory:
    ```bash
    python scripts/run_end_to_end_scenario_01.py
    ```

## Limitations of this Scenario

*   **Simplified Agent Interaction:** Agent-to-agent tasking via a full MCP is not implemented. The `LevelArchitectAgent` calls the toolchain bridge directly instead of tasking `PixelForgeAgent`.
*   **Mocked Logic:** Core agent decision-making, design processes, and toolchain generation are heavily mocked or simplified.
*   **No Real MCP:** Relies on a simple event log and direct function calls rather than a full MCP server with task queues, state management, and HTTP communication.
*   **Limited Error Handling:** Focuses on the "happy path" of the workflow.

This scenario serves as a basic structural test and a template for more complex end-to-end tests that could be developed with more comprehensive mocking or a test instance of the MCP.